{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA assignment 1 : Literature review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. My First Read\n",
    "\n",
    "Here I will outline what I encountered in my first read of *Opinion mining with Deep Recurrent Neural Networks* (Irsoy and Cardie, 2014). I am reading this paper with the following goals in mind.\n",
    "-  Improve the accuracy of opinion mining \n",
    "-  Investigate the usefulness of using a recurrent nerual network to achieve this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Read and Write Critical Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Content\n",
    "\n",
    "This paper is about Opinion Mining \"Fine-grained opinion analysis aims to detect subjective expressions in a text (e.g. \"hate\") and to characterize their intensity (e.g. strong) and sentiment (e.g. negative)\" (Irsoy and Cardie, 2014). Opinion mining is related to areas of computer science such as natural language processing, text analysis and computational linguistics. The goal of opinion mining, is to take an input sentence then output information describing the subjective expressions, intensity and sentiment.\n",
    "The authors achieve this by feeding a sentences into machine learning algorithms in an attempt to classify the sentences into either *direct subjective expressions* (DSEs) or *expressive subjective expressions* (ESEs) (Wiebe et al., 2005).\n",
    "\"DSE's consist of private states or speech events expressing private states; and ESE's consist of expressions that indicate sentiment, emotion, etc., without explicitly conveying them\" (Isroy and Cardie, 2014). In the past, opinion mining problems have been attempted to be solved as sequence labeling problems for example in the work of (Choi et al., 2005). To utilize research that has been undertaken in the past Isroy and Cardie used the BIO tagging scheme. The BIO tagging scheme is a simple tagging system where the B indicates the beginning of the of an opinion related expression, I corresponds to all of the tokens inside the opinion related expression, and the O indicates tokens outside any opinion related class. Below is the example provided in the paper:  \n",
    "<!-- This is how to make comments in Markdown style=\"float:left;\"-->\n",
    "<img  src=\"table1.PNG\">\n",
    "<ENTER>\n",
    "On inspection of this sentence in the figure above it is clear that there is expression and tone with the \"as usual\" and \"refused to make any statements\"\n",
    "<!-- Do a little more on the explanation on the tagging scheme -->\n",
    "When it comes to selecting a specific machine learning approach for the goal of classifying the subjective expression, intensity and sentiment. It can depend on the way in which the problem is viewed. For example in the paper *Identifying Sources of Opinions with Conditional Random Fields and Extraction Patterns* (Choi et al., 2005) they stated “We view this problem as an information extraction task and adopt a hybrid approach that combines Conditional Random Fields (Lafferty et at., 2001) and a variation of AutoSlog (Riloff, 1996a)”. This method was one of the approaches which was compared against the Recurrent Neural Network in the paper. Below is a short summary of each algorithm referenced in the paper.\n",
    "<ENTER>\n",
    "Conditional Random Field (CRF)<br>\n",
    "The conditional random field was one of the earlier attempts at a machine learning algorithm applied to Opinion Mining, Lafferty describes the CRF as “a framework for building probabilistic models to segment and label sequence data”\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <img src=\"https://media.giphy.com/media/K25wpPoaYmo9y/giphy.gif\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Innovation\n",
    "\n",
    "This paper is novel because it is one of the first attempts at applying Recurrent Neural Networks to the task of Opinion Mining. Using RNNs the authors found that they were able to achieve better results than the current state of the art algorithms at the time. Additionally it should be noted that the CRF and the semiCRF's had access to \"word vectors\". The RNN did not use the word vectors, this means that the CRFs and semiCRFs had access to more information. The word vectors are 300-dimensional data points (Mikilov et al, 2013). These word vectors were trained on the google news dataset which is around 100 billion words.\n",
    "<ENTER>\n",
    "Considering the fact that the RNNs outperformed the CRFs and semiCRFs without using the word vectors indicates that using RNNs is a very good approach for conducting Opinion Mining tasks. This paper has been well received in the papers that have sited it and it has been the foundation for the paper \"Fine-grained opinion analysis with Recurrent Neural Networks and Word Embeddings\" (Liu et al., 2015). Liu states in their paper that Isroy and Cardie's work was the foundation of their paper. However they used a different RNN architecture. Liu used Jordan and LSTM RNNs whereas Isroy and Cardie used Elman type RNNs.\n",
    "<ENTER>\n",
    "There is also other work that has cited this paper that is not in the realm of Natural Language Processing. Soggard and Goldberg's 2016 paper is looking at deep multi-task learning and they cite Isroy and Cardie's paper for their contribution to developing a sequence tagging architecture.<br>\n",
    "We can see that this work was novel and innovative it was one of the first implementations of using RNNs for opinion mining which other people have now utilized in their work. I would argue that Isroy and Cardie's paper was novel and innovative that achieved good results and paved the way for future research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Technical Quality\n",
    "\n",
    "Technically speaking I believe this paper is of high quality, it was authored by a distinguished scholar Claire Cardie with over 16,000 citations (Google Scholar, 2018). To me that indicates that the author is a respected academic in the community. However we should not judge the paper based on who wrote it, but rather the content of the paper itself. Having read the paper I believe that their research methodology is sound. In the paper Isroy and Cardie gave an explanation of their methodology which I will explain below. Giving a brief explanation of certain terms that may not be obvious to a non expert of the subject area. <br>\n",
    "Firstly they trained 6 recurrent neural networks, with one being a shallow recurrent neural network and the other five being deep recurrent neural networks they said \"We employ the standard softmax activation for the output layer: $g(x) = e^{x_i}$ <br>\n",
    "For the hidden layers we use the rectifier linear activation: $f(x) = max\\left\\{0, x\\right\\}$ Experimentally, rectifier activation gives better performance, faster convergence, and sparse representations.\" (Isroy and Cardie, 2014)<br>\n",
    "In addition to this they specify the dataset that they are using which is the \"MPQA 1.2 corpus (Wiebe et al., 2005)\". This dataset contains 535 news articles which contains 11,111 sentences. These sentences were manually annotated with the DSEs and ESEs so that they can test if their algorithm produced the correct classification of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 X-Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Presentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
